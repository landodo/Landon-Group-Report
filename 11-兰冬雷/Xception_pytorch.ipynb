{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jBZ5w9065Pl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torch.utils import data as D\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uf3TCIeB65Pr"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "validation_ratio = 0.1\n",
    "random_seed = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121,
     "referenced_widgets": [
      "abb964e12a0c484f9ca2283b4d3b6ec4",
      "afefca8955d84f2490b85803d1475a86",
      "9d2de6d746644b7fa45bed2369510424",
      "351a7afa56334748a807ed0c4e76e762",
      "e477ba7734c24bbd8d0ab4ebf6eaa374",
      "c1041eef6e9540dba74eade5d37f3851",
      "ffd77bd3647949489baff9183e82fae0",
      "797c1c3c9f6647ed97ba8b81d21eadef"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22685,
     "status": "ok",
     "timestamp": 1584338333889,
     "user": {
      "displayName": "hoya012",
      "photoUrl": "https://lh3.googleusercontent.com/-995djavMjjs/AAAAAAAAAAI/AAAAAAAAAVk/modB75beBwU/s64/photo.jpg",
      "userId": "15725788610401702262"
     },
     "user_tz": -540
    },
    "id": "J164BT6q65Pv",
    "outputId": "4004b53c-d4a7-4903-9d82-76fe44552c8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "        transforms.Resize(128),\n",
    "        transforms.RandomCrop(128, padding=32),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "transform_validation = transforms.Compose([\n",
    "        transforms.Resize(128),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.Resize(128),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "validset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_validation)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "#trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "#                                          shuffle=True, num_workers=0)\n",
    "\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(validation_ratio * num_train))\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, sampler=train_sampler, num_workers=0\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    validset, batch_size=batch_size, sampler=valid_sampler, num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "initial_lr = 0.045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObTXJ0dL65P1"
   },
   "outputs": [],
   "source": [
    "class depthwise_separable_conv(nn.Module):\n",
    "    def __init__(self, nin, nout, kernel_size, padding, bias=False):\n",
    "        super(depthwise_separable_conv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(nin, nin, kernel_size=kernel_size, padding=padding, groups=nin, bias=bias)\n",
    "        self.pointwise = nn.Conv2d(nin, nout, kernel_size=1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8JNdBwbf65P4"
   },
   "outputs": [],
   "source": [
    "class Xception(nn.Module):\n",
    "    def __init__(self, input_channel, num_classes=10):\n",
    "        super(Xception, self).__init__()\n",
    "        \n",
    "        # Entry Flow\n",
    "        self.entry_flow_1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.entry_flow_2 = nn.Sequential(\n",
    "            depthwise_separable_conv(64, 128, 3, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            depthwise_separable_conv(128, 128, 3, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.entry_flow_2_residual = nn.Conv2d(64, 128, kernel_size=1, stride=2, padding=0)\n",
    "        \n",
    "        self.entry_flow_3 = nn.Sequential(\n",
    "            nn.ReLU(True),\n",
    "            depthwise_separable_conv(128, 256, 3, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            \n",
    "            nn.ReLU(True),\n",
    "            depthwise_separable_conv(256, 256, 3, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.entry_flow_3_residual = nn.Conv2d(128, 256, kernel_size=1, stride=2, padding=0)\n",
    "        \n",
    "        self.entry_flow_4 = nn.Sequential(\n",
    "            nn.ReLU(True),\n",
    "            depthwise_separable_conv(256, 728, 3, 1),\n",
    "            nn.BatchNorm2d(728),\n",
    "            \n",
    "            nn.ReLU(True),\n",
    "            depthwise_separable_conv(728, 728, 3, 1),\n",
    "            nn.BatchNorm2d(728),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.entry_flow_4_residual = nn.Conv2d(256, 728, kernel_size=1, stride=2, padding=0)\n",
    "        \n",
    "        # Middle Flow\n",
    "        self.middle_flow = nn.Sequential(\n",
    "            nn.ReLU(True),\n",
    "            depthwise_separable_conv(728, 728, 3, 1),\n",
    "            nn.BatchNorm2d(728),\n",
    "            \n",
    "            nn.ReLU(True),\n",
    "            depthwise_separable_conv(728, 728, 3, 1),\n",
    "            nn.BatchNorm2d(728),\n",
    "            \n",
    "            nn.ReLU(True),\n",
    "            depthwise_separable_conv(728, 728, 3, 1),\n",
    "            nn.BatchNorm2d(728)\n",
    "        )\n",
    "        \n",
    "        # Exit Flow\n",
    "        self.exit_flow_1 = nn.Sequential(\n",
    "            nn.ReLU(True),\n",
    "            depthwise_separable_conv(728, 728, 3, 1),\n",
    "            nn.BatchNorm2d(728),\n",
    "            \n",
    "            nn.ReLU(True),\n",
    "            depthwise_separable_conv(728, 1024, 3, 1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.exit_flow_1_residual = nn.Conv2d(728, 1024, kernel_size=1, stride=2, padding=0)\n",
    "        self.exit_flow_2 = nn.Sequential(\n",
    "            depthwise_separable_conv(1024, 1536, 3, 1),\n",
    "            nn.BatchNorm2d(1536),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            depthwise_separable_conv(1536, 2048, 3, 1),\n",
    "            nn.BatchNorm2d(2048),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.linear = nn.Linear(2048, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        entry_out1 = self.entry_flow_1(x)\n",
    "        entry_out2 = self.entry_flow_2(entry_out1) + self.entry_flow_2_residual(entry_out1)\n",
    "        entry_out3 = self.entry_flow_3(entry_out2) + self.entry_flow_3_residual(entry_out2)\n",
    "        entry_out = self.entry_flow_4(entry_out3) + self.entry_flow_4_residual(entry_out3)\n",
    "        \n",
    "        middle_out = self.middle_flow(entry_out) + entry_out\n",
    "        \n",
    "        for i in range(7):\n",
    "          middle_out = self.middle_flow(middle_out) + middle_out\n",
    "\n",
    "        exit_out1 = self.exit_flow_1(middle_out) + self.exit_flow_1_residual(middle_out)\n",
    "        exit_out2 = self.exit_flow_2(exit_out1)\n",
    "\n",
    "        exit_avg_pool = F.adaptive_avg_pool2d(exit_out2, (1, 1))                \n",
    "        exit_avg_pool_flat = exit_avg_pool.view(exit_avg_pool.size(0), -1)\n",
    "\n",
    "        output = self.linear(exit_avg_pool_flat)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "850wCUVF65P7"
   },
   "outputs": [],
   "source": [
    "net = Xception(3, 10) #ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1584338342308,
     "user": {
      "displayName": "hoya012",
      "photoUrl": "https://lh3.googleusercontent.com/-995djavMjjs/AAAAAAAAAAI/AAAAAAAAAVk/modB75beBwU/s64/photo.jpg",
      "userId": "15725788610401702262"
     },
     "user_tz": -540
    },
    "id": "P5rgRS2565QA",
    "outputId": "1f13fa0c-14cf-40db-9bbf-a2e19f80c9cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9125,
     "status": "ok",
     "timestamp": 1584338352085,
     "user": {
      "displayName": "hoya012",
      "photoUrl": "https://lh3.googleusercontent.com/-995djavMjjs/AAAAAAAAAAI/AAAAAAAAAVk/modB75beBwU/s64/photo.jpg",
      "userId": "15725788610401702262"
     },
     "user_tz": -540
    },
    "id": "K1nTbMKw65QD",
    "outputId": "787b2db5-c6c9-409d-957c-651a6aba8a6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Xception(\n",
       "  (entry_flow_1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (entry_flow_2): Sequential(\n",
       "    (0): depthwise_separable_conv(\n",
       "      (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): depthwise_separable_conv(\n",
       "      (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "      (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (entry_flow_2_residual): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (entry_flow_3): Sequential(\n",
       "    (0): ReLU(inplace=True)\n",
       "    (1): depthwise_separable_conv(\n",
       "      (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "      (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): depthwise_separable_conv(\n",
       "      (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (entry_flow_3_residual): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (entry_flow_4): Sequential(\n",
       "    (0): ReLU(inplace=True)\n",
       "    (1): depthwise_separable_conv(\n",
       "      (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): depthwise_separable_conv(\n",
       "      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "      (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (entry_flow_4_residual): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (middle_flow): Sequential(\n",
       "    (0): ReLU(inplace=True)\n",
       "    (1): depthwise_separable_conv(\n",
       "      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "      (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): depthwise_separable_conv(\n",
       "      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "      (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): depthwise_separable_conv(\n",
       "      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "      (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (exit_flow_1): Sequential(\n",
       "    (0): ReLU(inplace=True)\n",
       "    (1): depthwise_separable_conv(\n",
       "      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "      (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): depthwise_separable_conv(\n",
       "      (depthwise): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "      (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (exit_flow_1_residual): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (exit_flow_2): Sequential(\n",
       "    (0): depthwise_separable_conv(\n",
       "      (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "      (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): depthwise_separable_conv(\n",
       "      (depthwise): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "      (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (linear): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Start at:  Fri Dec 11 08:35:43 2020\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.asctime(time.localtime(time.time()))\n",
    "print (\"Train Start at: \",start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8dALFTuL65QH",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   250] loss: 2.1078744\n",
      "[1,   500] loss: 1.7013918\n",
      "[0 epoch] Accuracy of the network on the validation images: 42 %\n",
      "[2,   250] loss: 1.3789000\n",
      "[2,   500] loss: 1.2187569\n",
      "[1 epoch] Accuracy of the network on the validation images: 56 %\n",
      "[3,   250] loss: 1.0353949\n",
      "[3,   500] loss: 0.9460982\n",
      "[2 epoch] Accuracy of the network on the validation images: 62 %\n",
      "[4,   250] loss: 0.8064175\n",
      "[4,   500] loss: 0.7470114\n",
      "[3 epoch] Accuracy of the network on the validation images: 67 %\n",
      "[5,   250] loss: 0.6502923\n",
      "[5,   500] loss: 0.6354827\n",
      "[4 epoch] Accuracy of the network on the validation images: 72 %\n",
      "[6,   250] loss: 0.5987351\n",
      "[6,   500] loss: 0.5660082\n",
      "[5 epoch] Accuracy of the network on the validation images: 74 %\n",
      "[7,   250] loss: 0.4956860\n",
      "[7,   500] loss: 0.4744828\n",
      "[6 epoch] Accuracy of the network on the validation images: 74 %\n",
      "[8,   250] loss: 0.5037934\n",
      "[8,   500] loss: 0.4528574\n",
      "[7 epoch] Accuracy of the network on the validation images: 76 %\n",
      "[9,   250] loss: 0.3893477\n",
      "[9,   500] loss: 0.3898181\n",
      "[8 epoch] Accuracy of the network on the validation images: 76 %\n",
      "[10,   250] loss: 0.3783518\n",
      "[10,   500] loss: 0.3650177\n",
      "[9 epoch] Accuracy of the network on the validation images: 77 %\n",
      "[11,   250] loss: 0.3137898\n",
      "[11,   500] loss: 0.3314004\n",
      "[10 epoch] Accuracy of the network on the validation images: 78 %\n",
      "[12,   250] loss: 0.4802624\n",
      "[12,   500] loss: 0.3640091\n",
      "[11 epoch] Accuracy of the network on the validation images: 77 %\n",
      "[13,   250] loss: 0.3035468\n",
      "[13,   500] loss: 0.3064248\n",
      "[12 epoch] Accuracy of the network on the validation images: 79 %\n",
      "[14,   250] loss: 0.2797937\n",
      "[14,   500] loss: 0.2865547\n",
      "[13 epoch] Accuracy of the network on the validation images: 79 %\n",
      "[15,   250] loss: 0.2390145\n",
      "[15,   500] loss: 0.2555036\n",
      "[14 epoch] Accuracy of the network on the validation images: 80 %\n",
      "[16,   250] loss: 0.2436917\n",
      "[16,   500] loss: 0.2438789\n",
      "[15 epoch] Accuracy of the network on the validation images: 78 %\n",
      "[17,   250] loss: 0.2153499\n",
      "[17,   500] loss: 0.2273009\n",
      "[16 epoch] Accuracy of the network on the validation images: 80 %\n",
      "[18,   250] loss: 0.2005612\n",
      "[18,   500] loss: 0.2011595\n",
      "[17 epoch] Accuracy of the network on the validation images: 81 %\n",
      "[19,   250] loss: 0.1808655\n",
      "[19,   500] loss: 0.1849401\n",
      "[18 epoch] Accuracy of the network on the validation images: 80 %\n",
      "[20,   250] loss: 0.1749664\n",
      "[20,   500] loss: 0.1758422\n",
      "[19 epoch] Accuracy of the network on the validation images: 81 %\n",
      "[21,   250] loss: 0.1600653\n",
      "[21,   500] loss: 0.1541128\n",
      "[20 epoch] Accuracy of the network on the validation images: 81 %\n",
      "[22,   250] loss: 0.1546641\n",
      "[22,   500] loss: 0.1579930\n",
      "[21 epoch] Accuracy of the network on the validation images: 81 %\n",
      "[23,   250] loss: 0.1358909\n",
      "[23,   500] loss: 0.1414411\n",
      "[22 epoch] Accuracy of the network on the validation images: 82 %\n",
      "[24,   250] loss: 0.1270603\n",
      "[24,   500] loss: 0.1295347\n",
      "[23 epoch] Accuracy of the network on the validation images: 82 %\n",
      "[25,   250] loss: 0.1158701\n",
      "[25,   500] loss: 0.1236949\n",
      "[24 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[26,   250] loss: 0.1141707\n",
      "[26,   500] loss: 0.1159905\n",
      "[25 epoch] Accuracy of the network on the validation images: 82 %\n",
      "[27,   250] loss: 0.1007193\n",
      "[27,   500] loss: 0.1026152\n",
      "[26 epoch] Accuracy of the network on the validation images: 82 %\n",
      "[28,   250] loss: 0.1053027\n",
      "[28,   500] loss: 0.1015101\n",
      "[27 epoch] Accuracy of the network on the validation images: 82 %\n",
      "[29,   250] loss: 0.0849384\n",
      "[29,   500] loss: 0.0954018\n",
      "[28 epoch] Accuracy of the network on the validation images: 82 %\n",
      "[30,   250] loss: 0.0882779\n",
      "[30,   500] loss: 0.0844315\n",
      "[29 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[31,   250] loss: 0.0755459\n",
      "[31,   500] loss: 0.0748325\n",
      "[30 epoch] Accuracy of the network on the validation images: 82 %\n",
      "[32,   250] loss: 0.0752830\n",
      "[32,   500] loss: 0.0764719\n",
      "[31 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[33,   250] loss: 0.0631574\n",
      "[33,   500] loss: 0.0670219\n",
      "[32 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[34,   250] loss: 0.0617852\n",
      "[34,   500] loss: 0.0604056\n",
      "[33 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[35,   250] loss: 0.0569031\n",
      "[35,   500] loss: 0.0589615\n",
      "[34 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[36,   250] loss: 0.0737599\n",
      "[36,   500] loss: 0.0597042\n",
      "[35 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[37,   250] loss: 0.0586099\n",
      "[37,   500] loss: 0.0551216\n",
      "[36 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[38,   250] loss: 0.0526482\n",
      "[38,   500] loss: 0.0513871\n",
      "[37 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[39,   250] loss: 0.0422603\n",
      "[39,   500] loss: 0.0478268\n",
      "[38 epoch] Accuracy of the network on the validation images: 82 %\n",
      "[40,   250] loss: 0.0431830\n",
      "[40,   500] loss: 0.0446909\n",
      "[39 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[41,   250] loss: 0.0364558\n",
      "[41,   500] loss: 0.0384867\n",
      "[40 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[42,   250] loss: 0.0416089\n",
      "[42,   500] loss: 0.0419357\n",
      "[41 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[43,   250] loss: 0.0371038\n",
      "[43,   500] loss: 0.0371064\n",
      "[42 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[44,   250] loss: 0.0331247\n",
      "[44,   500] loss: 0.0352282\n",
      "[43 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[45,   250] loss: 0.0281234\n",
      "[45,   500] loss: 0.0331068\n",
      "[44 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[46,   250] loss: 0.0387601\n",
      "[46,   500] loss: 0.0318495\n",
      "[45 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[47,   250] loss: 0.0287145\n",
      "[47,   500] loss: 0.0295377\n",
      "[46 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[48,   250] loss: 0.0369417\n",
      "[48,   500] loss: 0.0265885\n",
      "[47 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[49,   250] loss: 0.0251548\n",
      "[49,   500] loss: 0.0263732\n",
      "[48 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[50,   250] loss: 0.0434540\n",
      "[50,   500] loss: 0.0312673\n",
      "[49 epoch] Accuracy of the network on the validation images: 83 %\n",
      "[51,   250] loss: 0.0225699\n",
      "[51,   500] loss: 0.0266013\n",
      "[50 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[52,   250] loss: 0.0220982\n",
      "[52,   500] loss: 0.0241781\n",
      "[51 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[53,   250] loss: 0.0184493\n",
      "[53,   500] loss: 0.0201668\n",
      "[52 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[54,   250] loss: 0.0218614\n",
      "[54,   500] loss: 0.0212918\n",
      "[53 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[55,   250] loss: 0.0181113\n",
      "[55,   500] loss: 0.0210739\n",
      "[54 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[56,   250] loss: 0.0246859\n",
      "[56,   500] loss: 0.0180740\n",
      "[55 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[57,   250] loss: 0.0174577\n",
      "[57,   500] loss: 0.0167248\n",
      "[56 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[58,   250] loss: 0.0227070\n",
      "[58,   500] loss: 0.0154899\n",
      "[57 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[59,   250] loss: 0.0145918\n",
      "[59,   500] loss: 0.0163994\n",
      "[58 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[60,   250] loss: 0.0179376\n",
      "[60,   500] loss: 0.0164890\n",
      "[59 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[61,   250] loss: 0.0120257\n",
      "[61,   500] loss: 0.0136571\n",
      "[60 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[62,   250] loss: 0.0164738\n",
      "[62,   500] loss: 0.0130985\n",
      "[61 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[63,   250] loss: 0.0122985\n",
      "[63,   500] loss: 0.0102551\n",
      "[62 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[64,   250] loss: 0.0107730\n",
      "[64,   500] loss: 0.0142992\n",
      "[63 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[65,   250] loss: 0.0121013\n",
      "[65,   500] loss: 0.0125776\n",
      "[64 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[66,   250] loss: 0.0318173\n",
      "[66,   500] loss: 0.0177379\n",
      "[65 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[67,   250] loss: 0.0136800\n",
      "[67,   500] loss: 0.0133418\n",
      "[66 epoch] Accuracy of the network on the validation images: 84 %\n",
      "[68,   250] loss: 0.0126889\n",
      "[68,   500] loss: 0.0129200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[69,   250] loss: 0.0112317\n",
      "[69,   500] loss: 0.0116105\n",
      "[68 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[70,   250] loss: 0.0119080\n",
      "[70,   500] loss: 0.0097267\n",
      "[69 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[71,   250] loss: 0.0115536\n",
      "[71,   500] loss: 0.0094735\n",
      "[70 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[72,   250] loss: 0.0105987\n",
      "[72,   500] loss: 0.0119858\n",
      "[71 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[73,   250] loss: 0.0121387\n",
      "[73,   500] loss: 0.0092085\n",
      "[72 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[74,   250] loss: 0.0070642\n",
      "[74,   500] loss: 0.0081908\n",
      "[73 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[75,   250] loss: 0.0099117\n",
      "[75,   500] loss: 0.0085511\n",
      "[74 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[76,   250] loss: 0.0076440\n",
      "[76,   500] loss: 0.0074626\n",
      "[75 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[77,   250] loss: 0.0062244\n",
      "[77,   500] loss: 0.0096577\n",
      "[76 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[78,   250] loss: 0.0081819\n",
      "[78,   500] loss: 0.0065762\n",
      "[77 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[79,   250] loss: 0.0055625\n",
      "[79,   500] loss: 0.0073242\n",
      "[78 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[80,   250] loss: 0.0081289\n",
      "[80,   500] loss: 0.0065801\n",
      "[79 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[81,   250] loss: 0.0080191\n",
      "[81,   500] loss: 0.0067672\n",
      "[80 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[82,   250] loss: 0.0091357\n",
      "[82,   500] loss: 0.0081149\n",
      "[81 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[83,   250] loss: 0.0083918\n",
      "[83,   500] loss: 0.0087531\n",
      "[82 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[84,   250] loss: 0.0056003\n",
      "[84,   500] loss: 0.0057701\n",
      "[83 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[85,   250] loss: 0.0061889\n",
      "[85,   500] loss: 0.0051294\n",
      "[84 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[86,   250] loss: 0.0063507\n",
      "[86,   500] loss: 0.0059396\n",
      "[85 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[87,   250] loss: 0.0060617\n",
      "[87,   500] loss: 0.0079281\n",
      "[86 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[88,   250] loss: 0.0060172\n",
      "[88,   500] loss: 0.0050122\n",
      "[87 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[89,   250] loss: 0.0036895\n",
      "[89,   500] loss: 0.0054657\n",
      "[88 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[90,   250] loss: 0.0064730\n",
      "[90,   500] loss: 0.0071091\n",
      "[89 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[91,   250] loss: 0.0056076\n",
      "[91,   500] loss: 0.0047377\n",
      "[90 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[92,   250] loss: 0.0052442\n",
      "[92,   500] loss: 0.0053140\n",
      "[91 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[93,   250] loss: 0.0052133\n",
      "[93,   500] loss: 0.0055943\n",
      "[92 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[94,   250] loss: 0.0061436\n",
      "[94,   500] loss: 0.0037984\n",
      "[93 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[95,   250] loss: 0.0058168\n",
      "[95,   500] loss: 0.0047448\n",
      "[94 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[96,   250] loss: 0.0044690\n",
      "[96,   500] loss: 0.0049961\n",
      "[95 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[97,   250] loss: 0.0047672\n",
      "[97,   500] loss: 0.0040327\n",
      "[96 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[98,   250] loss: 0.0055643\n",
      "[98,   500] loss: 0.0037597\n",
      "[97 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[99,   250] loss: 0.0034475\n",
      "[99,   500] loss: 0.0045113\n",
      "[98 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[100,   250] loss: 0.0049196\n",
      "[100,   500] loss: 0.0043493\n",
      "[99 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[101,   250] loss: 0.0052216\n",
      "[101,   500] loss: 0.0046963\n",
      "[100 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[102,   250] loss: 0.0044481\n",
      "[102,   500] loss: 0.0040119\n",
      "[101 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[103,   250] loss: 0.0037515\n",
      "[103,   500] loss: 0.0044648\n",
      "[102 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[104,   250] loss: 0.0044892\n",
      "[104,   500] loss: 0.0041154\n",
      "[103 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[105,   250] loss: 0.0034194\n",
      "[105,   500] loss: 0.0041636\n",
      "[104 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[106,   250] loss: 0.0035675\n",
      "[106,   500] loss: 0.0046522\n",
      "[105 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[107,   250] loss: 0.0034231\n",
      "[107,   500] loss: 0.0042649\n",
      "[106 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[108,   250] loss: 0.0040298\n",
      "[108,   500] loss: 0.0039121\n",
      "[107 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[109,   250] loss: 0.0037955\n",
      "[109,   500] loss: 0.0031334\n",
      "[108 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[110,   250] loss: 0.0043019\n",
      "[110,   500] loss: 0.0039885\n",
      "[109 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[111,   250] loss: 0.0037174\n",
      "[111,   500] loss: 0.0031499\n",
      "[110 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[112,   250] loss: 0.0044050\n",
      "[112,   500] loss: 0.0041636\n",
      "[111 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[113,   250] loss: 0.0032088\n",
      "[113,   500] loss: 0.0038616\n",
      "[112 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[114,   250] loss: 0.0037744\n",
      "[114,   500] loss: 0.0036387\n",
      "[113 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[115,   250] loss: 0.0032333\n",
      "[115,   500] loss: 0.0027883\n",
      "[114 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[116,   250] loss: 0.0034194\n",
      "[116,   500] loss: 0.0026087\n",
      "[115 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[117,   250] loss: 0.0021975\n",
      "[117,   500] loss: 0.0028611\n",
      "[116 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[118,   250] loss: 0.0029720\n",
      "[118,   500] loss: 0.0044415\n",
      "[117 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[119,   250] loss: 0.0038551\n",
      "[119,   500] loss: 0.0027357\n",
      "[118 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[120,   250] loss: 0.0026606\n",
      "[120,   500] loss: 0.0032779\n",
      "[119 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[121,   250] loss: 0.0026804\n",
      "[121,   500] loss: 0.0036855\n",
      "[120 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[122,   250] loss: 0.0026897\n",
      "[122,   500] loss: 0.0032359\n",
      "[121 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[123,   250] loss: 0.0036553\n",
      "[123,   500] loss: 0.0041091\n",
      "[122 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[124,   250] loss: 0.0032643\n",
      "[124,   500] loss: 0.0034761\n",
      "[123 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[125,   250] loss: 0.0026608\n",
      "[125,   500] loss: 0.0040761\n",
      "[124 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[126,   250] loss: 0.0026380\n",
      "[126,   500] loss: 0.0021082\n",
      "[125 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[127,   250] loss: 0.0032954\n",
      "[127,   500] loss: 0.0037990\n",
      "[126 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[128,   250] loss: 0.0028140\n",
      "[128,   500] loss: 0.0030236\n",
      "[127 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[129,   250] loss: 0.0028834\n",
      "[129,   500] loss: 0.0031183\n",
      "[128 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[130,   250] loss: 0.0039143\n",
      "[130,   500] loss: 0.0034973\n",
      "[129 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[131,   250] loss: 0.0016813\n",
      "[131,   500] loss: 0.0029175\n",
      "[130 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[132,   250] loss: 0.0027880\n",
      "[132,   500] loss: 0.0025465\n",
      "[131 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[133,   250] loss: 0.0039116\n",
      "[133,   500] loss: 0.0034565\n",
      "[132 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[134,   250] loss: 0.0030665\n",
      "[134,   500] loss: 0.0030498\n",
      "[133 epoch] Accuracy of the network on the validation images: 86 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[135,   250] loss: 0.0030490\n",
      "[135,   500] loss: 0.0020285\n",
      "[134 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[136,   250] loss: 0.0040877\n",
      "[136,   500] loss: 0.0036548\n",
      "[135 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[137,   250] loss: 0.0031683\n",
      "[137,   500] loss: 0.0027891\n",
      "[136 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[138,   250] loss: 0.0026111\n",
      "[138,   500] loss: 0.0037556\n",
      "[137 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[139,   250] loss: 0.0028837\n",
      "[139,   500] loss: 0.0034781\n",
      "[138 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[140,   250] loss: 0.0025157\n",
      "[140,   500] loss: 0.0020306\n",
      "[139 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[141,   250] loss: 0.0022864\n",
      "[141,   500] loss: 0.0033019\n",
      "[140 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[142,   250] loss: 0.0023374\n",
      "[142,   500] loss: 0.0021323\n",
      "[141 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[143,   250] loss: 0.0029830\n",
      "[143,   500] loss: 0.0026743\n",
      "[142 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[144,   250] loss: 0.0024923\n",
      "[144,   500] loss: 0.0026146\n",
      "[143 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[145,   250] loss: 0.0017612\n",
      "[145,   500] loss: 0.0031088\n",
      "[144 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[146,   250] loss: 0.0025228\n",
      "[146,   500] loss: 0.0031492\n",
      "[145 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[147,   250] loss: 0.0023881\n",
      "[147,   500] loss: 0.0034650\n",
      "[146 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[148,   250] loss: 0.0022417\n",
      "[148,   500] loss: 0.0021370\n",
      "[147 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[149,   250] loss: 0.0025878\n",
      "[149,   500] loss: 0.0032328\n",
      "[148 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[150,   250] loss: 0.0024920\n",
      "[150,   500] loss: 0.0033428\n",
      "[149 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[151,   250] loss: 0.0025919\n",
      "[151,   500] loss: 0.0027105\n",
      "[150 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[152,   250] loss: 0.0027436\n",
      "[152,   500] loss: 0.0035176\n",
      "[151 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[153,   250] loss: 0.0020813\n",
      "[153,   500] loss: 0.0022240\n",
      "[152 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[154,   250] loss: 0.0022741\n",
      "[154,   500] loss: 0.0024855\n",
      "[153 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[155,   250] loss: 0.0020212\n",
      "[155,   500] loss: 0.0024496\n",
      "[154 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[156,   250] loss: 0.0028731\n",
      "[156,   500] loss: 0.0034748\n",
      "[155 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[157,   250] loss: 0.0027407\n",
      "[157,   500] loss: 0.0021514\n",
      "[156 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[158,   250] loss: 0.0023955\n",
      "[158,   500] loss: 0.0020414\n",
      "[157 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[159,   250] loss: 0.0022236\n",
      "[159,   500] loss: 0.0028842\n",
      "[158 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[160,   250] loss: 0.0023741\n",
      "[160,   500] loss: 0.0027341\n",
      "[159 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[161,   250] loss: 0.0018917\n",
      "[161,   500] loss: 0.0024527\n",
      "[160 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[162,   250] loss: 0.0029795\n",
      "[162,   500] loss: 0.0015014\n",
      "[161 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[163,   250] loss: 0.0018990\n",
      "[163,   500] loss: 0.0027845\n",
      "[162 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[164,   250] loss: 0.0027757\n",
      "[164,   500] loss: 0.0020061\n",
      "[163 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[165,   250] loss: 0.0025747\n",
      "[165,   500] loss: 0.0032532\n",
      "[164 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[166,   250] loss: 0.0030257\n",
      "[166,   500] loss: 0.0028665\n",
      "[165 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[167,   250] loss: 0.0028003\n",
      "[167,   500] loss: 0.0025854\n",
      "[166 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[168,   250] loss: 0.0037320\n",
      "[168,   500] loss: 0.0021234\n",
      "[167 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[169,   250] loss: 0.0021324\n",
      "[169,   500] loss: 0.0028804\n",
      "[168 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[170,   250] loss: 0.0020898\n",
      "[170,   500] loss: 0.0025412\n",
      "[169 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[171,   250] loss: 0.0023761\n",
      "[171,   500] loss: 0.0029430\n",
      "[170 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[172,   250] loss: 0.0020323\n",
      "[172,   500] loss: 0.0028294\n",
      "[171 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[173,   250] loss: 0.0015253\n",
      "[173,   500] loss: 0.0020818\n",
      "[172 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[174,   250] loss: 0.0026538\n",
      "[174,   500] loss: 0.0026940\n",
      "[173 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[175,   250] loss: 0.0022194\n",
      "[175,   500] loss: 0.0022911\n",
      "[174 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[176,   250] loss: 0.0022467\n",
      "[176,   500] loss: 0.0022120\n",
      "[175 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[177,   250] loss: 0.0026406\n",
      "[177,   500] loss: 0.0028550\n",
      "[176 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[178,   250] loss: 0.0022597\n",
      "[178,   500] loss: 0.0028486\n",
      "[177 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[179,   250] loss: 0.0020362\n",
      "[179,   500] loss: 0.0025921\n",
      "[178 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[180,   250] loss: 0.0021241\n",
      "[180,   500] loss: 0.0028593\n",
      "[179 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[181,   250] loss: 0.0018245\n",
      "[181,   500] loss: 0.0032487\n",
      "[180 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[182,   250] loss: 0.0025811\n",
      "[182,   500] loss: 0.0023134\n",
      "[181 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[183,   250] loss: 0.0016276\n",
      "[183,   500] loss: 0.0021857\n",
      "[182 epoch] Accuracy of the network on the validation images: 85 %\n",
      "[184,   250] loss: 0.0037570\n",
      "[184,   500] loss: 0.0017745\n",
      "[183 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[185,   250] loss: 0.0030020\n",
      "[185,   500] loss: 0.0020985\n",
      "[184 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[186,   250] loss: 0.0025530\n",
      "[186,   500] loss: 0.0030716\n",
      "[185 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[187,   250] loss: 0.0018812\n",
      "[187,   500] loss: 0.0026140\n",
      "[186 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[188,   250] loss: 0.0035114\n",
      "[188,   500] loss: 0.0022442\n",
      "[187 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[189,   250] loss: 0.0028399\n",
      "[189,   500] loss: 0.0030017\n",
      "[188 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[190,   250] loss: 0.0021538\n",
      "[190,   500] loss: 0.0022238\n",
      "[189 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[191,   250] loss: 0.0022629\n",
      "[191,   500] loss: 0.0024178\n",
      "[190 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[192,   250] loss: 0.0026031\n",
      "[192,   500] loss: 0.0018577\n",
      "[191 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[193,   250] loss: 0.0019058\n",
      "[193,   500] loss: 0.0031233\n",
      "[192 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[194,   250] loss: 0.0022766\n",
      "[194,   500] loss: 0.0023194\n",
      "[193 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[195,   250] loss: 0.0022375\n",
      "[195,   500] loss: 0.0021492\n",
      "[194 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[196,   250] loss: 0.0034841\n",
      "[196,   500] loss: 0.0027367\n",
      "[195 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[197,   250] loss: 0.0019502\n",
      "[197,   500] loss: 0.0020695\n",
      "[196 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[198,   250] loss: 0.0023790\n",
      "[198,   500] loss: 0.0026829\n",
      "[197 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[199,   250] loss: 0.0029993\n",
      "[199,   500] loss: 0.0019856\n",
      "[198 epoch] Accuracy of the network on the validation images: 86 %\n",
      "[200,   250] loss: 0.0030558\n",
      "[200,   500] loss: 0.0011285\n",
      "[199 epoch] Accuracy of the network on the validation images: 87 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=initial_lr, momentum=0.9)\n",
    "\n",
    "for epoch in range(200):\n",
    "    if epoch == 0:\n",
    "        lr = initial_lr\n",
    "    elif epoch % 2 == 0 and epoch != 0:\n",
    "        lr *= 0.94\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        show_period = 250\n",
    "        if i % show_period == show_period-1:    # print every \"show_period\" mini-batches\n",
    "            print('[%d, %5d] loss: %.7f' %\n",
    "                  (epoch + 1, i + 1, running_loss / show_period))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        \n",
    "    #validation part\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(valid_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('[%d epoch] Accuracy of the network on the validation images: %d %%' % \n",
    "          (epoch, 100 * correct / total)\n",
    "         )\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Finish at:  Sat Dec 12 00:24:28 2020\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.asctime(time.localtime(time.time()))\n",
    "print (\"Train Finish at: \", start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WM4hcitG65QO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 86 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYQ6TjYe65QR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 89 %\n",
      "Accuracy of   car : 88 %\n",
      "Accuracy of  bird : 81 %\n",
      "Accuracy of   cat : 74 %\n",
      "Accuracy of  deer : 86 %\n",
      "Accuracy of   dog : 79 %\n",
      "Accuracy of  frog : 91 %\n",
      "Accuracy of horse : 91 %\n",
      "Accuracy of  ship : 92 %\n",
      "Accuracy of truck : 88 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "                \n",
    "        for i in range(labels.shape[0]):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjkHTRvH65QU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Xception_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "351a7afa56334748a807ed0c4e76e762": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_797c1c3c9f6647ed97ba8b81d21eadef",
      "placeholder": "",
      "style": "IPY_MODEL_ffd77bd3647949489baff9183e82fae0",
      "value": "170500096it [00:30, 15909372.39it/s]"
     }
    },
    "797c1c3c9f6647ed97ba8b81d21eadef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d2de6d746644b7fa45bed2369510424": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1041eef6e9540dba74eade5d37f3851",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e477ba7734c24bbd8d0ab4ebf6eaa374",
      "value": 1
     }
    },
    "abb964e12a0c484f9ca2283b4d3b6ec4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d2de6d746644b7fa45bed2369510424",
       "IPY_MODEL_351a7afa56334748a807ed0c4e76e762"
      ],
      "layout": "IPY_MODEL_afefca8955d84f2490b85803d1475a86"
     }
    },
    "afefca8955d84f2490b85803d1475a86": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1041eef6e9540dba74eade5d37f3851": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e477ba7734c24bbd8d0ab4ebf6eaa374": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ffd77bd3647949489baff9183e82fae0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
